As a starting place, the following blog post provides A Review of Popular Deep Learning Architectures: AlexNet, VGG16, and GoogleNet. https://blog.paperspace.com/popular-deep-learning-architectures-alexnet-vgg-googlenet/
Beyond describing the evolution of design architectures, that link and blog post is useful in that it also has links (most of which still work) to implementations in both PyTorch and Tensorflow for versions of each of the models.

Although we will not be outlining the original 2015 conference paper, Very Deep Convolutional Networks for Large-Scale Image Recognition, by Simonyan and Zisserman (chrome-extension://oemmndcbldboiebfnladdacbdfmadadm/https://arxiv.org/pdf/1409.1556.pdf) the first 3:40 of this video may serve as a useful resource to unpack the ConvNet configurations graph, after which the video goes through the process of constructing such an architecture in PyTorch. The first 13:30 of this video (https://www.youtube.com/watch?v=ACmuBbuXn20) also offers a good breakdown of the VGGNet architecture, and this link for VGG16 Keras implementation https://github.com/krishnaik06/Advanced-CNN-Architectures

We will use this article (https://cs231n.github.io/convolutional-networks/#overview) to talk about Convolutional Neural Networks (CNNs/ConvNets), and this video (https://www.youtube.com/watch?v=-I0lry5ceDs) can serve as a primer for understanding that process.
