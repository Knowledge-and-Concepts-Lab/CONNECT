---
title: "Building a pattern associator"
output: html_notebook
---
ls
Let's make a simple pattern associator that has 5 input units and 6 output units. First we can make a matrix of input and a matrix of target patterns. Let's just use random patterns for now:

```{r}
inputs <- matrix(sample(c(-1,1), 50, replace = T), 10, 5)
outputs <- matrix(sample(c(-1,1), 60, replace = T), 10, 6)

head(outputs)
```
*inputs* is now a matrix in which each column represents one input unit, and each row represents the pattern of activation over units for a given item. Same for *outputs*. There are 5 input units and 6 output units, and 10 patterns for each. How could you double-check this? (hint: dim function).

A pattern associator takes an input pattern and sends it through a bank of weights to generate net inputs for the output units. So, we need a weight matrix. Since there are 5 input units each sending one connection to each of the 6 output units, the dimensions of the weight matrix should be 5 x 6. Let's make a matrix with zero weights:

```{r}
w <- matrix(0, dim(inputs)[2], dim(outputs)[2])
```

*Test yourself:* Why did I use dim(inputs)[2] and dim(outputs)[2] instead of just specifying the numbers 5 and 6?

Remember the net input for a receiving unit is the activation of the sending unit times the weight, summed across all sending units. (I am ignoring bias weights in this exercise). Each row of *inputs* is one input pattern, and each column of _w_ encodes the weights going from the inputs to an output unit. So for input pattern 1, we could compute the net input for output unit 2 as follows:

```{r}
sum(inputs[1,] * w[,1])
```
We could then loop over each output unit, collecting this sum into a vector to get net inputs for all receiving units. But that is tedious: recall that matrix multiplication does this automatically for us:

```{r}
inputs[1,] %*% w
```

In R, matrix operations are enclosed in percent symbols---so the weird looking operator just indications that we are treating this product as a matrix multiplication. That then generates, in one line, a vector indicating the net inputs for all receiving units given pattern 1 as input.

Even more convenient: we do not need to feed the patterns in one at a time. We can use matrix multiplication to compute the net inputs for each pattern in the input matrix:

```{r}
inputs %*% w
```
*Test yourself:* Why are these all zeroes?

Finally, we need to set activation values for all the output units given their net inputs. In class we discussed two: _threshold_ functions (+1 if input above 0, -1 otherwise) and _linear_ functions (activation = net input). For linear we can just uste the net input as the activation, but let's write a function to return the activation for each unit given its net input:

```{r}
thresh <- function(net){
  o <- net > 0 #is net input above zero, true or false?
  o <- apply(o, 2, FUN="as.numeric") #apply as.numeric to each column of o
  (o- 0.5) * 2 #convert from {0,1} to {-1,1}
}
```

The statement `net > 0` inside the parentheses evaluates, for every element of the _net_ argument, whether it is greater than zero, returning the binary TRUE if so and FALSE otherwise. We want to convert these from binary TRUE/FALSE to numerical values -1 1. The `as.numeric` function will convert the binary object to a number, changing TRUE to 1 and FALSE to 0. To get these numbers to -1,1 we then need to subtract .5 (so all numbers will be -0.5 or +0.5) and then multiply by 2 (all numbers now -1,1). Let's try it:

```{r}
thresh(inputs %*% w)
```
*Test yourself:* Why are these numbers all -1?

We could get more interesting/varied inputs if we created a weight matrix that wasn't all zero-valued. Here is a random weight matrix with values ranging from -1 to 1:

```{r}
# Let's make variables to code number of input and output units:
ninputs <- dim(inputs)[2]
noutputs <- dim(outputs)[2]

#
tmp <- 2 * (runif(ninputs * noutputs) - .5) #Random values from -1 to 1
w <- matrix(tmp, ninputs, noutputs)
```

Now we can look at net inputs generated by random weight matrix:

```{r}
inputs %*% w
```
...and pass these through the activation function:

```{r}
thresh(inputs%*%w)
```
Now we are getting some varied outputs! Onward toward Hebbian learning...

## Hebbian Learning

First, let's replace the weight matrix with an all-zero matrix again to make things simple:

```{r}
w <- matrix(0, ninputs, noutputs)
```

Recall that in Hebbian learning, the weight change from $a_i$ (sending) to $a_j$ (receiving) on each pattern is just the $\epsilon a_i a_j$, where $\epsilon$ is some constant learning rate. Thus the total weight change across all of the training patterns is the sum of this product across the training patterns.

Our input patterns are stored in the 10x5 matrix _inputs_, and our output patterns are stored in the 10x6 matrix _outputs_. The activations of input unit 1 across all 10 patterns are in `inputs[,1]` and the corresponding target activations for output unit 1 are in `outputs[,1]. For now let's just set $\epsilon = 1$ so we don't need to worry about this _learning rate constant_. That means that the change in the weight going from input unit 1 to output unit 1 will just be:

```{r}
sum(inputs[,1] * outputs[,1])
```
*Note:* Your result will vary depending on the particular random patterns generated earlier!

The line looks kinda sorta like what we did to compute the net input for a single output unit---it is _dot product_ of two vectors. Rather than computing this separately for every weight in the model, can we again use matrix multiplication? You might be tempted to try this:

```{r}
#This will produce an error:
inputs %*% outputs
```
The error arises because matrix multiplication takes each _row_ of a left-hand matrix (in this case `inputs`) and multiplies it by each _column_ of the right-hand matrix. So the left-hand matrix has to have the same number of rows as the right-hand matrix has columns. Our `inputs` matrix has 10 rows (10 patterns) while the `outputs` matrix has only 6 columns (6 output units). For this computation, we want to sum over _patterns_ (not units), so we want to orient the two matrices so that the left-hand one has columns that indicate pattern number and the right-hand one has rows that indicate the pattern number. Here is one way to do this:

```{r}
t(inputs) %*% outputs
```
The `t()` function _transposes_ the matrix, flipping rows and columns. So `t(inputs)` reorients the input matrix so that columns indicate patterns 1-10 and rows indicate input units 1-5. With that one matrix multiplication, we have computed, for every weight in the model, how that weight should change in order to store the input and output patterns.

What if we want the weight changes to not be so large---like, weights should move in the correct direction but maybe not that whole way? Easy-peasy: we can just multiply the whole matrix by the learning rate constant $\epsilon$. Say we want the weights to only be half the size for instance:

```{r}
t(inputs) %*% outputs * 0.5
```

Recall this output just tells us how the current weights should change with Hebbian learning. To implement the weight change, we still need to add these values back in to the original weight matrix:

```{r}
epsilon <- 0.5 #Set a learning rate
w_delta <- epsilon * t(inputs) %*% outputs #Change in weights
w <- w + w_delta #Update weights

w
```
Now you can see that we have a much more interesting weight matrix than the all-zero matrix we started with! NB your results will differ depending on the particular input and output patterns you have.

How well is the network doing? We can test it by passing inputs through the new weights and applying the threshold activation function:

```{r}
thresh(inputs %*% w)
```
Okay, we get some outputs, but how do we know if they are correct? We can compare the outputs generated to what the outputs should have been:

```{r}
acts <- thresh(inputs %*% w) #Compute output activations
acts==outputs #Show where model has produced correct outputs
```
Probably it is not doing perfectly, since Hebbian learning is pretty limited! Your results will differ. You can check what proportion of output units it is getting right by tacking the matrix mean:

```{r}
mean(acts==outputs)
```

Not perfect but better than chance. You can also look to see how well it is doing on each unit:

```{r}
colMeans(acts==outputs)
```
Better on some units than others. Finally, you could try doing another round of Hebbian learning. Recall that the weight changes _only depend_ on the input and target unit activations---so computing the weight changes again will return exactly the same values as the first time. So another update will just involve adding these change values to the existing weights:

```{r}
w <- w + w_delta
w
```
The weights will have doubled compared to previously, but this will not change the behavior of the thresholded output units:

```{r}
acts <- thresh(inputs %*% w) #Compute output activations
acts==outputs #Show where model has produced correct outputs
```
...this should be identical to the output above.

That's all there is to it for the simplest form of Hebbian learning!

## Delta rule learning

Recall that, in delta rule learning, (a) we use a _linear_ activation function and (b) we first use the current weights to generate an _output activation_ for each input pattern, then compute the _error_ of this generated pattern compared to the target pattern it should have produced.

Let's reset the weight matrix back to all zeroes:

```{r}
w <- matrix(0, ninputs, noutputs)
```

*Test yourself*: How do we now get the model to generate predicted output activations for the input patterns?

For Hebbian learning, we computed a weight-change matrix `w_delta` across all patterns, then multiplied this by the learning-rate constant $\epsilon$ and added the changes to the existing weight matrix. For delta-rule learning we can do the same thing--the only difference is in how the `w_delta` is computed. Recall from class that the delta change rule for each weight is $\epsilon (t - a_j) a_i$. 

The target activations for each unit and pattern are just the desired output values stored in `outputs`. To get the output patterns generated by the current weight matrix for each input pattern, we do the same matrix multiplication as previously: `inputs %*% w`. Since we are using a linear activation function, there is no need to pass this through the threshold function---the output activation is equal to the net input. So setting \$epsilon$ to 1 (so we can ignore it for now), the first part of the delta rule change equation is just this:

```{r}
outputs - inputs %*% w
```
This gives you, for each pattern (rows) and output unit (columns), the difference between the desired activation and the activations the current weight matrix is generating. However, to figure out how to change the weights, we need to additionally multiply these numbers by the _input activation_ for the corresponding sending unit for each pattern. Here again we make use of matrix multiplication, transposing the input pattern matrix on the left-hand side:

```{r}
acts <- inputs %*% w #Compute output activations
w_delta <- t(inputs) %*% (outputs - acts)
w_delta
```

Now you can see we have a weight-change matrix of the correct dimension (5 rows for 5 sending units, 6 columns for 6 receiving units). The values are pretty big though! Let's make sure the actual weight changes we implement are a lot smaller by using a small learning-rate constant:

```{r}
epsilon <- 0.01
acts <- inputs %*% w #Compute output activations
w_delta <- epsilon * t(inputs) %*% (outputs - acts)
w_delta
```
As before we can update the weight by adding this matrix to the original weights.

*Key difference from Hebbian learning:* Once we have changed the weights, the model predictions for each input pattern will be _different_, which means that the error generated by each input pattern will be _different_. Unlike Hebbian learning, weight changes will differ with each pass through the training data. We can see this by implementing the above weight change, then computing the new weight-change matrix:

```{r}
w <- w + w_delta #Update weights
acts <- inputs %*% w #Compute new output activations
w_delta <- epsilon * t(inputs) %*% (outputs - acts) #compute new deltas
w_delta
```
Compare this to the earlier `w_delta` values. Numbers are diffrent! If we now update the weights again and re-compute these changes, they will change again, and again, and again.

*Test yourself:* What is a useful thing to do, programming-wise, when you have to do the same computation over and over again?

First, let's write a function that will automatically update the weight matrix:

```{r}
wt.update <- function(ins, outs, wts, ep = 0.01){
  acts <- ins %*% wts
  w_delta <- ep * t(ins) %*% (outs - acts)
  wts + w_delta
}
```

...we can try it out:

```{r}
wt.update(inputs, outputs, w)
```
Now say we want to run this function over and over again to train the model. Let's use a loop!

```{r}
for(i in c(1:100)){
  w <- wt.update(inputs, outputs, w)
}

w
```
We just ran our updating procedure a hundred times and got the above weight matrix. I wonder how well it is doing? One way of answering this question is to see what the total error is. We should write a function to compute that!

```{r}
get.error <- function(acts, targs){
  mean((targs - acts)^2)
}

acts <- inputs %*% w

get.error(acts, outputs)
```
So we have a number---is it any good? Hard to say, but it is something we can track over the course of learning if we add it to our loop:
```{r}
w <- matrix(0, 5, 6) #Reset weight matrix

epsilon = 0.01 #Set learning rate
nepochs = 50 #Number of training epochs

errvec <- c() #Initialize vector to store total error.

for(i in c(1:nepochs)){
  w <- wt.update(inputs, outputs, w, epsilon) #Update weights
  acts <- inputs %*% w #Compute output activations
  errvec <- append(errvec, get.error(acts, outputs)) #COmpute total error
}

plot(errvec, type = "l")

```




We can use it to generate outputs and compare these to the true outputs:

```{r}
acts <- inputs %*% w

thresh(acts) == outputs

```

